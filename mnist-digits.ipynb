{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, BatchNormalization, Flatten, Dense\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work with the Data\n",
    "* Change the data into the required format\n",
    "* Augment the data slightly\n",
    "* Split the data into train and validation sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CHANGING INTO REQUIRED FORMAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../input/digit-recognizer/train.csv')\n",
    "test = pd.read_csv('../input/digit-recognizer/test.csv')\n",
    "#Converts panda dataframe into numpy arrays\n",
    "train = train.to_numpy() \n",
    "test = test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train[:, 0] #Seperate all labels in train set\n",
    "x_train = train[:, 1:] #Seperate all pixel values in train set\n",
    "x_test = test[:, :] #Get all pixel values for test set\n",
    "x_train = np.reshape(x_train, (-1, 28, 28, 1))\n",
    "x_test = np.reshape(x_test, (-1, 28, 28, 1))\n",
    "print(y_train.shape, x_train.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AUGMENT THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rescale = 1./255., \n",
    "                             rotation_range = 15,\n",
    "                             height_shift_range = 0.15,\n",
    "                             width_shift_range = 0.15,\n",
    "                             zoom_range = 0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SPLIT THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size = 0.2)\n",
    "print(x_train.shape, y_train.shape, x_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the model\n",
    "### Train two slightly different models simultaneously:\n",
    "#### First model contains maxpooling layer after convolution layer, Second model contains convolution layer with stride 2 after a convolution layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = 2 #Number of neural networks (models)\n",
    "model = [0] * nn\n",
    "\n",
    "#Build model\n",
    "for i in range(nn):\n",
    "    model[i] = tf.keras.models.Sequential()\n",
    "    model[i].add(Conv2D(32, (3, 3), activation = 'relu', input_shape = (28, 28, 1)))\n",
    "    model[i].add(BatchNormalization())\n",
    "    model[i].add(Conv2D(32, (3, 3), activation = 'relu'))\n",
    "    model[i].add(BatchNormalization())\n",
    "    if(i == 0):\n",
    "        model[i].add(MaxPooling2D(2, 2))\n",
    "    else:\n",
    "        model[i].add(Conv2D(32, (5, 5), strides = (2, 2), padding = 'same', activation = 'relu'))\n",
    "    model[i].add(BatchNormalization())\n",
    "    model[i].add(Dropout(0.4))\n",
    "    \n",
    "    model[i].add(Conv2D(64, (3, 3), activation = 'relu'))\n",
    "    model[i].add(BatchNormalization())\n",
    "    model[i].add(Conv2D(64, (3, 3), activation = 'relu'))\n",
    "    model[i].add(BatchNormalization())\n",
    "    if(i == 0):\n",
    "        model[i].add(MaxPooling2D(2, 2))\n",
    "    else:\n",
    "        model[i].add(Conv2D(64, (5, 5), strides = (2, 2), padding = 'same', activation = 'relu'))\n",
    "    model[i].add(BatchNormalization())\n",
    "    model[i].add(Dropout(0.4))\n",
    "    \n",
    "    model[i].add(Flatten())\n",
    "    model[i].add(Dense(128, activation = 'relu'))\n",
    "    model[i].add(Dropout(0.4))\n",
    "    model[i].add(Dense(10, activation = 'softmax'))\n",
    "    \n",
    "#Compile model\n",
    "for i in range(nn):\n",
    "    model[i].compile(loss = 'sparse_categorical_crossentropy',\n",
    "                     optimizer = 'adam',\n",
    "                     metrics = ['accuracy'])\n",
    "\n",
    "#Summarize models\n",
    "for i in range(nn):\n",
    "    model[i].summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = [0] * nn\n",
    "epochs = 10\n",
    "steps_per_epoch = 50\n",
    "for i in range(nn):\n",
    "    history[i] = model[i].fit(x_train, y_train,\n",
    "                              batch_size = 32,\n",
    "                              steps_per_epoch = steps_per_epoch,\n",
    "                              epochs = epochs,\n",
    "                              validation_data = (x_val, y_val),\n",
    "                              verbose = 1)\n",
    "    print(\"Model {}, acc: {}, validation acc: {}\".format(i, max(history[i].history['accuracy']), max(history[i].history['val_accuracy'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_1 = history[0].history['accuracy']\n",
    "vacc_1 = history[0].history['val_accuracy']\n",
    "acc_2 = history[1].history['accuracy']\n",
    "vacc_2 = history[1].history['val_accuracy']\n",
    "\n",
    "# epochs = range(len(acc_1)) \n",
    "epochs = range(1, 11)\n",
    "\n",
    "plt.plot(epochs, acc_1, 'b', label = 'Training Accuracy - Model 1')\n",
    "plt.plot(epochs, vacc_1, 'b--', label = 'Validation Accuracy - Model 1')\n",
    "plt.plot(epochs, acc_2, 'r', label = 'Training Accuracy - Model 2')\n",
    "plt.plot(epochs, vacc_2, 'r--', label = 'Validation Accuracy - Model 2')\n",
    "\n",
    "plt.title('Training and Validation accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig('./comparison_10.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
